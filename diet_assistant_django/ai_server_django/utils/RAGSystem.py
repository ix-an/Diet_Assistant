"""
RAGSystem æ¨¡å—

åŠŸèƒ½è¯´æ˜ï¼š
- åŸºäº Chroma å‘é‡æ•°æ®åº“å®ç°æ–‡æ¡£æ£€ç´¢
- ä½¿ç”¨ DashScope(OpenAI-compatible) Embedding API è¿›è¡Œå‘é‡å¬å›
- ä½¿ç”¨æœ¬åœ° CrossEncoderï¼ˆäºŒæ¬¡ç²¾æ’æ¨¡å‹ï¼‰å¯¹å¬å›ç»“æœè¿›è¡Œé‡æ’åºï¼ˆå¼ƒç”¨ï¼‰
- ä½¿ç”¨ FlagEmbedding å®˜æ–¹ BGE æ¨¡å‹é‡æ’åºå™¨ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
- è¿”å›ä¸ç”¨æˆ·é—®é¢˜æœ€ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µï¼Œä¾›ä¸Šå±‚ LLM ä½¿ç”¨
"""

import chromadb
import os
from dotenv import load_dotenv
from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction
# from sentence_transformers import CrossEncoder  # å¼ƒç”¨
from FlagEmbedding import FlagReranker  # BGEæ¨¡å‹å®˜æ–¹é‡æ’åºå™¨ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰


# =================================================
# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
# =================================================
load_dotenv('asst.env')
openai_api_key = os.getenv("OPENAI_API_KEY")
api_base_url = os.getenv("API_BASE_URL")
rerank_model = os.getenv("RERANK_MODEL")

# =================================================
# RAGSystemï¼šè´Ÿè´£å‘é‡å¬å› + äºŒæ¬¡ç²¾æ’
# å¯¹å¤–æä¾› retrieval_chunks æ–¹æ³•
# =================================================
class RAGSystem:
    def __init__(
        self,
        host = "localhost",
        port=8081,
        collection_name="my_collection",  # å‘é‡é›†åˆåç§°
        rerank_model_path=rerank_model,  # æœ¬åœ°äºŒæ¬¡ç²¾æ’æ¨¡å‹è·¯å¾„
    ):
        # åˆå§‹åŒ– Chroma å®¢æˆ·ç«¯
        chroma_client = chromadb.HttpClient(host=host, port=port)

        # è·å– / åˆ›å»ºå‘é‡é›†åˆ
        self.collection = chroma_client.get_or_create_collection(
            name=collection_name,
            embedding_function=OpenAIEmbeddingFunction(
                api_key=openai_api_key,
                model_name="text-embedding-v4",
                api_base=api_base_url,
                api_type="dashscope",
            ),
        )

        # # åŠ è½½æœ¬åœ° CrossEncoder äºŒæ¬¡ç²¾æ’æ¨¡å‹
        # self.model = CrossEncoder(rerank_model_path)  # å¼ƒç”¨

        # åŠ è½½ FlagEmbedding å®˜æ–¹ BGE æ¨¡å‹é‡æ’åºå™¨
        self.model = FlagReranker(
            rerank_model_path,
            use_fp16=True  # å¯ç”¨FP16ç²¾åº¦ (GPUåŠ é€Ÿï¼Œæå‡æ¨ç†é€Ÿåº¦ï¼‰
        )

    # =================================================
    # æ ¹æ®ç”¨æˆ·é—®é¢˜æ£€ç´¢ç›¸å…³æ–‡æ¡£ç‰‡æ®µ
    # =================================================
    def retrieval_chunks(
        self,
        question,
        n_results=30,  # å‘é‡å¬å›æ•°é‡
        rerank=True,  # æ˜¯å¦å¯ç”¨äºŒæ¬¡ç²¾æ’
        rank_threshold=0.2,  # ç²¾æ’å¾—åˆ†é˜ˆå€¼
        top_k=5,  # æœ€ç»ˆè¿”å›çš„æ–‡æ¡£ç‰‡æ®µæ•°é‡
    ):

        # å‘é‡å¬å›
        result = self.collection.query(
            query_texts=[question],
            n_results=n_results
        )

        # æå–æ–‡æ¡£å†…å®¹å’Œå…ƒæ•°æ®ï¼ˆChromaDBè¿”å›æ ¼å¼ï¼šåˆ—è¡¨çš„åˆ—è¡¨ï¼‰
        documents = result["documents"][0]
        metadatas = result["metadatas"][0]

        # ----------------------------------------
        # é‡æ’åºé€»è¾‘
        # ----------------------------------------
        if rerank and documents:
            print(f"ğŸ” åˆå§‹æ£€ç´¢ç»“æœ: {len(documents)} ä¸ªå€™é€‰æ–‡æ¡£")

            # æ„é€ è¾“å…¥å¯¹ï¼Œæ‰¹é‡è®¡ç®—å¾—åˆ†ï¼Œæå‡æ•ˆç‡
            pairs = [(question, doc) for doc in documents]

            # ä½¿ç”¨BGEæ¨¡å‹æ‰¹é‡è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
            scores = self.model.compute_score(pairs)

            # å°†åˆ†æ•°ä¸æ–‡æ¡£ã€å…ƒæ•°æ®ç»„åˆå¹¶æ’åº
            combined = []
            for i in range(len(documents)):
                combined.append({
                    "doc": documents[i],  # æ–‡æ¡£å†…å®¹
                    "meta": metadatas[i],  # å…ƒæ•°æ®ï¼ˆå¦‚sourceã€departmentï¼‰
                    "score": scores[i]  # BGEç›¸å…³æ€§å¾—åˆ†
                })

            # æŒ‰BGEå¾—åˆ†é™åºæ’åº
            combined.sort(key=lambda x: x["score"], reverse=True)

            # è¿‡æ»¤å¹¶æˆªå–top_kä¸ªæ–‡æ¡£
            chunks, metas = [], []
            for item in combined:
                # å¾—åˆ†è¿‡ä½æˆ–æ•°é‡è¾¾åˆ°ä¸Šé™å³åœæ­¢
                if item["score"] < rank_threshold or len(chunks) >= top_k:
                     break
                chunks.append(item["doc"])
                metas.append(item["meta"])

            return {
                "documents": chunks,
                "metadatas": metas,
            }

        # æœªå¯ç”¨é‡æ’åºæˆ–æ— ç»“æœ
        return {
            "documents": documents[:top_k],
            "metadatas": metadatas[:top_k],
        }

